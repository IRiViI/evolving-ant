{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from antAgent import Ant, DataObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import roboschool\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training environments\n",
    "# The creature will have to do multiple environments to obtain it's score\n",
    "envs = []\n",
    "number_of_envs = 3\n",
    "for i in range(number_of_envs):\n",
    "    env = gym.make('RoboschoolAnt-v1')\n",
    "    envs.append(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "max_number_of_steps = 500\n",
    "number_of_agents = 300\n",
    "number_of_previous_agents = 300\n",
    "\n",
    "hidden_layer_widths = [64,32]\n",
    "\n",
    "children_ratio = 0.2\n",
    "mutation_ratio = 0.6\n",
    "\n",
    "mutation_distance = 0.05\n",
    "mutation_chance = 0.05\n",
    "\n",
    "falling_reward = -500\n",
    "additional_moving_forward_reward_multiplier = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save settings\n",
    "log_file_path = './log_file.csv'\n",
    "savepoint_dir = './agents_weights/auto_savepoints'\n",
    "saving_interval_time = 10 * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the creatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new agents\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# Get information about environment\n",
    "env = envs[0]\n",
    "env.reset()\n",
    "action = env.action_space.sample()\n",
    "obv, reward, is_done, info = env.step(action)\n",
    "\n",
    "input_shape = np.array(obv).shape\n",
    "output_shape = np.array(action).shape\n",
    "\n",
    "# Headers of save file\n",
    "headers = ['episode', 'agent_number', 'id', \n",
    "           'parent_0', 'parent_1', \n",
    "           'fitness_value', \n",
    "           'mutated', 'cloned', \n",
    "           'mutation_distance', 'mutation_chance', 'max_number_of_steps'\n",
    "]\n",
    "    \n",
    "# Create agents\n",
    "print('Create new agents')\n",
    "# Reset graphs if any\n",
    "tf.compat.v1.reset_default_graph()\n",
    "agents = []\n",
    "for i in range(number_of_agents):\n",
    "    print(i)\n",
    "    agent = Ant(input_shape, output_shape, \n",
    "                hidden_layer_widths = hidden_layer_widths)\n",
    "    agent.build()\n",
    "    agents.append(agent)\n",
    "reward_history = []\n",
    "logs = []  \n",
    "episode_number = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights of the creatures\n",
    "\n",
    "(Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto save model\n",
    "load_episode = 1\n",
    "clean_start = False\n",
    "loadpoint_dir = './agents_weights/auto_savepoints/{}'.format(load_episode)\n",
    "\n",
    "# Pretrained models 128 32 layers model\n",
    "# load_episode = '128_32'\n",
    "# clean_start = True\n",
    "# loadpoint_dir = './agents_weights/{}'.format(load_episode)\n",
    "\n",
    "# Pretrained models 64 32 layers model\n",
    "# load_episode = '64_32'\n",
    "# clean_start = True\n",
    "# loadpoint_dir = './agents_weights/{}'.format(load_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./agents_weights/128_32/0.h5\n",
      "./agents_weights/128_32/1.h5\n",
      "./agents_weights/128_32/2.h5\n",
      "./agents_weights/128_32/3.h5\n",
      "./agents_weights/128_32/4.h5\n",
      "./agents_weights/128_32/5.h5\n",
      "./agents_weights/128_32/6.h5\n",
      "./agents_weights/128_32/7.h5\n",
      "./agents_weights/128_32/8.h5\n",
      "./agents_weights/128_32/9.h5\n",
      "./agents_weights/128_32/10.h5\n",
      "./agents_weights/128_32/11.h5\n",
      "./agents_weights/128_32/12.h5\n",
      "./agents_weights/128_32/13.h5\n",
      "./agents_weights/128_32/14.h5\n",
      "./agents_weights/128_32/15.h5\n",
      "./agents_weights/128_32/16.h5\n",
      "./agents_weights/128_32/17.h5\n",
      "./agents_weights/128_32/18.h5\n",
      "./agents_weights/128_32/19.h5\n",
      "./agents_weights/128_32/20.h5\n",
      "./agents_weights/128_32/21.h5\n",
      "./agents_weights/128_32/22.h5\n",
      "./agents_weights/128_32/23.h5\n",
      "./agents_weights/128_32/24.h5\n",
      "./agents_weights/128_32/25.h5\n",
      "./agents_weights/128_32/26.h5\n",
      "./agents_weights/128_32/27.h5\n",
      "./agents_weights/128_32/28.h5\n",
      "./agents_weights/128_32/29.h5\n"
     ]
    }
   ],
   "source": [
    "# Load previous saves\n",
    "with open(log_file_path, mode='r') as log_file:\n",
    "    csv_reader = csv.DictReader(log_file)\n",
    "    data = [row for row in csv_reader]\n",
    "    number_of_rows = len(data)\n",
    "    for agent_index, agent in enumerate(agents):\n",
    "\n",
    "        print('{}/{}.h5'.format(loadpoint_dir, agent_index))\n",
    "\n",
    "        agent_index = agent_index % number_of_previous_agents\n",
    "\n",
    "        agent.model.load_weights('{}/{}.h5'.format(loadpoint_dir, agent_index))\n",
    "\n",
    "        # Don't insert the previous values\n",
    "        if clean_start == True:\n",
    "            continue\n",
    "\n",
    "        row = None\n",
    "        for iRow in reversed(data):\n",
    "            if (int(iRow['episode']) == load_episode) and (int(iRow['agent_number']) == agent_index):\n",
    "                row = iRow\n",
    "                break\n",
    "        if row == None:\n",
    "            raise ValueError('Data of agent not found')\n",
    "\n",
    "        agent.data.id = row['id']\n",
    "        agent.data.parents = [row['parent_0'],row['parent_1']]\n",
    "        agent.data.fitness_value = row['fitness_value']\n",
    "        agent.data.mutated=row['mutated']\n",
    "        agent.data.cloned=row['cloned']\n",
    "\n",
    "    if clean_start == False:\n",
    "        episode_number = int(row['episode'])    \n",
    "    if clean_start == True:    \n",
    "        episode_number=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the creatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Start test...\n",
      "Agent 0 done with a total reward of 3658.684831079843\n",
      "Agent 1 done with a total reward of 3929.650385108821\n",
      "Agent 2 done with a total reward of 4658.686957961907\n",
      "Agent 3 done with a total reward of 5175.784237813082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-17c19c8f156b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mobvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_number_of_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/evolving-ant/antAgent.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0maction_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction_probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1113\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3037\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3038\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    749\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/_weakrefset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_IterationGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitemref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitemref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create logfile\n",
    "file_exists = os.path.isfile(log_file_path)\n",
    "with open(log_file_path, mode='a') as log_file:\n",
    "    # log writer\n",
    "    log_writer = csv.writer(log_file, delimiter=',')\n",
    "    # Create header if they do not exist\n",
    "    if not file_exists:\n",
    "        log_writer.writerow(headers)\n",
    "        \n",
    "# Adjust mutation rate and muation distance\n",
    "for agent in agents:\n",
    "    agent.mutation_distance = mutation_distance\n",
    "    agent.mutation_chance = mutation_chance\n",
    "\n",
    "# Initiate save timer\n",
    "# 0 if you want to safe the first generation, time.time() if you want to save at the end of the period\n",
    "last_save_time = 0 # int(time.time()) \n",
    "\n",
    "# Keep on running\n",
    "while True:\n",
    "    episode_number += 1\n",
    "    print('Round {}'.format(episode_number))\n",
    "    # Valuate the agents\n",
    "    print('Start test...')\n",
    "    total_rewards = []\n",
    "    for agent_index, agent in enumerate(agents):\n",
    "        total_reward = 0 \n",
    "        obvs = []\n",
    "        is_dones = []\n",
    "        for env in envs:\n",
    "            obv = env.reset()\n",
    "            obvs.append(obv)\n",
    "            is_dones.append(False)\n",
    "        obvs = np.array(obvs)\n",
    "        for step_number in range(max_number_of_steps):\n",
    "            actions = agent.predict(obvs)\n",
    "\n",
    "            for index, (env, action) in enumerate(zip(envs, actions)):\n",
    "                if is_dones[index]:\n",
    "                    continue\n",
    "                obv, reward, is_done, info = env.step(action)\n",
    "                reward += additional_moving_forward_reward_multiplier * env.rewards[1]\n",
    "                obvs[index] = obv\n",
    "                is_dones[index] = is_done\n",
    "                if is_dones[index]:\n",
    "                    print('Number {} is done at: {}'.format(index, step_number))\n",
    "                    reward += falling_reward\n",
    "                total_reward += reward\n",
    "\n",
    "        print('Agent {} done with a total reward of {}'.format(agent_index, total_reward))\n",
    "        total_rewards.append(total_reward)\n",
    "        agent.data.fitness_value = total_reward\n",
    "\n",
    "    # Save the rewards of this round\n",
    "    reward_history.append(total_rewards)\n",
    "\n",
    "    with open(log_file_path, mode='a') as log_file:\n",
    "        # log writer\n",
    "        log_writer = csv.writer(log_file, delimiter=',')\n",
    "        for agent_number, agent in enumerate(agents):\n",
    "            data = agent.data\n",
    "            if len(data.parents) > 0:\n",
    "                parent_id_0 = data.parents[0]\n",
    "            else: \n",
    "                parent_id_0 = ''\n",
    "            if len(data.parents) > 1:\n",
    "                parent_id_1 = data.parents[1]\n",
    "            else: \n",
    "                parent_id_1 = ''\n",
    "            log_writer.writerow([\n",
    "                episode_number,\n",
    "                agent_number,\n",
    "                data.id,\n",
    "                parent_id_0,\n",
    "                parent_id_1,\n",
    "                data.fitness_value,\n",
    "                data.mutated,\n",
    "                data.cloned,\n",
    "                agent.mutation_distance,\n",
    "                agent.mutation_chance,\n",
    "                max_number_of_steps,\n",
    "                ])\n",
    "\n",
    "    # Save data\n",
    "    log = []\n",
    "    for agent in agents:\n",
    "        log.append(agent.data)\n",
    "    logs.append(log)\n",
    "\n",
    "    # Save models\n",
    "    current_time = int(time.time())\n",
    "    if current_time - last_save_time > saving_interval_time:\n",
    "        last_save_time = current_time\n",
    "        for agent_index, agent in enumerate(agents):\n",
    "            total_save_dir = '{}/{}'.format(savepoint_dir, episode_number)\n",
    "            try:\n",
    "                # Create target Directory\n",
    "                os.mkdir(total_save_dir)\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "                \n",
    "            print('saving:{}'.format(agent_index))\n",
    "            agent.model.save_weights('{}/{}.h5'.format(total_save_dir, agent_index))\n",
    "\n",
    "    # Sexy time\n",
    "    print('Initiate sex...')\n",
    "    new_weights = []\n",
    "    datas = []\n",
    "\n",
    "    # Get the sexy time probabilities\n",
    "    print('Get probabilities')\n",
    "    total_rewards = np.array(total_rewards)\n",
    "    normalized_rewards = (total_rewards - min(total_rewards)) / (max(total_rewards) - min(total_rewards))\n",
    "    normalized_rewards /= sum(normalized_rewards)\n",
    "    # Let's squire it\n",
    "    normalized_rewards = normalized_rewards**2/np.sum(normalized_rewards**2)\n",
    "#     normalized_rewards = normalized_rewards**4/np.sum(normalized_rewards**4)\n",
    "\n",
    "    # Part of the new generation is new children\n",
    "\n",
    "    # Partner set 1\n",
    "    print('Create partner set 1')\n",
    "    partner_set_1 = []\n",
    "    for i in range(int(children_ratio * number_of_agents)):\n",
    "        agent = np.random.choice(agents, p=normalized_rewards)\n",
    "        partner_set_1.append(agent)\n",
    "\n",
    "    # Partner set 2\n",
    "    print('Create partner set 2')\n",
    "    partner_set_2 = []\n",
    "    for i in range(int(children_ratio * number_of_agents)):\n",
    "        agent = np.random.choice(agents, p=normalized_rewards)\n",
    "        partner_set_2.append(agent)\n",
    "\n",
    "    # Determine the new weights\n",
    "    print('Determine new weights')\n",
    "    for partner_1, partner_2 in zip(partner_set_1, partner_set_2):\n",
    "        child_weights = partner_1.get_child_weights_with_partner_and_mutate(partner_2)\n",
    "        new_weights.append(child_weights)\n",
    "        # Create new data structures\n",
    "        data =  DataObject({\n",
    "            'parents':[partner_1.data.id, partner_2.data.id],\n",
    "            'fitness_value': 0,\n",
    "            'mutated': True,\n",
    "            'cloned': False\n",
    "        })\n",
    "        datas.append(data)\n",
    "\n",
    "    # Part of the new generation is the a mutatant clone\n",
    "\n",
    "    # Determine mutant clones\n",
    "    print('Determine mutant clones')\n",
    "    while len(new_weights) < mutation_ratio * number_of_agents:\n",
    "        clone_parent_index = np.random.choice(range(0,number_of_agents), p=normalized_rewards)\n",
    "        agent = agents[clone_parent_index]\n",
    "        new_weights.append(agent.get_mutated_weights())\n",
    "        # Create new data structures\n",
    "        data =  DataObject({\n",
    "            'parents':[agent.data.id],\n",
    "            'fitness_value': 0,\n",
    "            'mutated': True,\n",
    "            'cloned': True\n",
    "        })\n",
    "        datas.append(data)\n",
    "\n",
    "    # Part of the new generation is the previous once\n",
    "\n",
    "    # Determine survivors\n",
    "    print('Determine survivors')\n",
    "    survivor_indices = []\n",
    "    while len(new_weights) < number_of_agents:\n",
    "        survivor_index = np.random.choice(range(0,number_of_agents), p=normalized_rewards)\n",
    "        if survivor_index not in survivor_indices:\n",
    "            survivor_indices.append(survivor_index)\n",
    "            agent = agents[survivor_index]\n",
    "            new_weights.append(agent.model.get_weights())\n",
    "                # Create new data structures\n",
    "            data =  DataObject({\n",
    "                'parents':[agent.data.id],\n",
    "                'fitness_value': 0,\n",
    "                'mutated': False,\n",
    "                'cloned': False\n",
    "            })\n",
    "            datas.append(data)\n",
    "\n",
    "    # Execute new era\n",
    "\n",
    "    # Create the next generation\n",
    "    print('Create new generation')\n",
    "\n",
    "    for agent, weights, data in zip(agents, new_weights, datas):\n",
    "        agent.set_weights(weights)\n",
    "        agent.data = data\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-92a1d9e3855b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Sort the reward history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msorted_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get the number of spiders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mamount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# Np reward history object\n",
    "history = np.array(reward_history)\n",
    "# Sort the reward history\n",
    "sorted_history = np.sort(history, axis=1)\n",
    "# Get the number of spiders\n",
    "amount = sorted_history.shape[1]\n",
    "# Plot values\n",
    "plt.plot(sorted_history[:,0])\n",
    "plt.plot(sorted_history[:,int(0.1 * amount-1)])\n",
    "plt.plot(sorted_history[:,int(0.25 * amount-1)])\n",
    "plt.plot(sorted_history[:,int(0.5 * amount-1)])\n",
    "plt.plot(sorted_history[:,int(0.75 * amount-1)])\n",
    "plt.plot(sorted_history[:,int(0.9 * amount-1)])\n",
    "plt.plot(sorted_history[:,int(amount-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
